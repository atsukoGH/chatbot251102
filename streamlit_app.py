import streamlit as st
import requests

# Show title and description.
st.title("ğŸ’¬ Chatbot (Gemini APIç‰ˆ)")
st.write(
    "ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯Google Gemini APIï¼ˆGenerative Language APIï¼‰ã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
    "åˆ©ç”¨ã™ã‚‹ã«ã¯ã€Google Gemini APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚APIã‚­ãƒ¼ã¯[ã“ã¡ã‚‰](https://makersuite.google.com/app/apikey)ã‹ã‚‰å–å¾—ã§ãã¾ã™ã€‚"
    "å…ƒã®OpenAIç‰ˆã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã¯[ã“ã¡ã‚‰](https://docs.streamlit.io/develop/tutorials/llms/build-conversational-apps)ã§ã™ã€‚"
)

# Ask user for their Gemini API key via `st.text_input`.
gemini_api_key = st.text_input("Gemini API Key", type="password")
if not gemini_api_key:
    st.info("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", icon="ğŸ—ï¸")
else:
    # Gemini API endpoint
    GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent"

    # Create a session state variable to store the chat messages.
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display the existing chat messages.
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Create a chat input field.
    if prompt := st.chat_input("ä½•ã‹è©±ã—ã‹ã‘ã¦ã¿ã¦ãã ã•ã„ï¼"):
        # Store and display the current prompt.
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Gemini API expects dialog history as a list of message dicts.
        gemini_history = []
        for m in st.session_state.messages:
            if m["role"] == "user":
                gemini_history.append({"role": "user", "parts": [m["content"]]})
            elif m["role"] == "assistant":
                gemini_history.append({"role": "model", "parts": [m["content"]]})

        # Prepare the API payload.
        payload = {
            "contents": gemini_history
        }
        headers = {
            "Content-Type": "application/json"
        }
        params = {
            "key": gemini_api_key
        }

        # Call the Gemini API.
        try:
            response = requests.post(GEMINI_API_URL, headers=headers, params=params, json=payload, timeout=30)
            response.raise_for_status()
            data = response.json()

            # Extract the model's reply.
            model_reply = ""
            if "candidates" in data and len(data["candidates"]) > 0:
                parts = data["candidates"][0].get("content", {}).get("parts", [])
                if parts:
                    model_reply = parts[0].get("text", "")
            else:
                model_reply = "ã‚¨ãƒ©ãƒ¼: Geminiã‹ã‚‰æœ‰åŠ¹ãªå¿œç­”ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"

        except Exception as e:
            model_reply = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        # Stream the response and store it.
        with st.chat_message("assistant"):
            st.markdown(model_reply)
        st.session_state.messages.append({"role": "assistant", "content": model_reply})
