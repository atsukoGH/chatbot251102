import streamlit as st
import google.generativeai as genai

import io
import PyPDF2
import docx

st.title("ğŸ’¬ Chatbot (Gemini 2.5 Pro + ãƒ•ã‚¡ã‚¤ãƒ«è³ªå•å¯¾å¿œ)")
st.write(
    "ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯Google Gemini 2.5 Pro APIã‚’ä½¿ã£ã¦è¿”ç­”ã—ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒ»PDFãƒ»Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€è«–æ–‡å½¢å¼ã®å ´åˆã¯ç ”ç©¶ã®èƒŒæ™¯ãƒ»ç›®çš„ï¼ˆ10è¡Œç¨‹åº¦ï¼‰ã€çµè«–ï¼ˆ5è¡Œç¨‹åº¦ï¼‰ã‚’è¦ç´„ã—ã¾ã™ã€‚ãã‚Œä»¥å¤–ã¯5è¡Œç¨‹åº¦ã§è¦ç´„ã—ã¾ã™ã€‚"
)
gemini_api_key = st.secrets.get("GEMINI_API_KEY")

uploaded_file = st.file_uploader(
    "è³ªå•ã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆtxt/pdf/docxå¯¾å¿œï¼‰",
    type=["txt", "pdf", "docx"]
)

def extract_text_from_file(uploaded_file):
    if uploaded_file is None:
        return None
    name = uploaded_file.name.lower()
    if name.endswith(".txt"):
        try:
            return uploaded_file.read().decode("utf-8")
        except Exception:
            uploaded_file.seek(0)
            return uploaded_file.read().decode("shift-jis", errors="ignore")
    elif name.endswith(".pdf"):
        try:
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() or ""
            return text
        except Exception as e:
            st.error(f"PDFã®èª­ã¿å–ã‚Šã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    elif name.endswith(".docx"):
        try:
            doc = docx.Document(uploaded_file)
            text = "\n".join([para.text for para in doc.paragraphs])
            return text
        except Exception as e:
            st.error(f"Wordãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿å–ã‚Šã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    else:
        st.error("æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚")
        return None

def is_likely_academic_paper(text):
    """ç°¡æ˜“çš„ã«è«–æ–‡å½¢å¼ã‹ã©ã†ã‹åˆ¤å®šã™ã‚‹ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã‚„ã‚»ã‚¯ã‚·ãƒ§ãƒ³åã€å‚è€ƒæ–‡çŒ®ã€abstractãªã©ã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰"""
    keywords = [
        "abstract", "introduction", "ç›®çš„", "èƒŒæ™¯", "æ–¹æ³•", "results", "è€ƒå¯Ÿ", "discussion", "conclusion", "çµè«–", "references", "å‚è€ƒæ–‡çŒ®"
    ]
    count = sum(k.lower() in text.lower() for k in keywords)
    return count >= 3

if not gemini_api_key:
    st.info("ç¶šè¡Œã™ã‚‹ã«ã¯Gemini APIã‚­ãƒ¼ã‚’secretsã«è¨­å®šã—ã¦ãã ã•ã„ã€‚", icon="ğŸ—ï¸")
else:
    genai.configure(api_key=gemini_api_key)

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "file_content" not in st.session_state:
        st.session_state.file_content = ""
    if "file_summary" not in st.session_state:
        st.session_state.file_summary = ""

    if uploaded_file is not None:
        file_content = extract_text_from_file(uploaded_file)
        st.session_state.file_content = file_content or ""
        if file_content:
            try:
                model = genai.GenerativeModel("gemini-2.5-pro")
                if is_likely_academic_paper(file_content):
                    summary_prompt = (
                        "æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆãŒç ”ç©¶è«–æ–‡ã‚„è«–æ–‡å½¢å¼ã®å ´åˆã¯ã€\n"
                        "ãƒ»ç ”ç©¶ã®èƒŒæ™¯ã‚„ç›®çš„ã«ã¤ã„ã¦10è¡Œç¨‹åº¦ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                        "ãƒ»çµè«–ã«ã¤ã„ã¦5è¡Œç¨‹åº¦ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n"
                        "ã€ãƒ†ã‚­ã‚¹ãƒˆã€‘\n" + file_content
                    )
                else:
                    summary_prompt = (
                        "æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’5è¡Œç¨‹åº¦ã®æ—¥æœ¬èªã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ï¼š\n\n" + file_content
                    )
                response = model.generate_content(summary_prompt)
                summary = response.text.strip()
                st.session_state.file_summary = summary
                st.success("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
                if is_likely_academic_paper(file_content):
                    st.markdown("#### ç ”ç©¶è«–æ–‡ã®è¦ç‚¹ã¾ã¨ã‚")
                else:
                    st.markdown("#### ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®è¦ç´„ï¼ˆç´„5è¡Œï¼‰")
                st.markdown(summary)
            except Exception as e:
                st.session_state.file_summary = f"è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                st.error(st.session_state.file_summary)
        else:
            st.session_state.file_summary = "ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            st.error(st.session_state.file_summary)

    def convert_role(role):
        if role == "assistant":
            return "model"
        return role

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    prompt = st.chat_input("ã”ç”¨ä»¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if prompt:
        context = ""
        if st.session_state.file_content:
            context += f"ã€å‚è€ƒãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã€‘\n{st.session_state.file_content}\n\n"
        prompt_with_context = context + prompt

        st.session_state.messages.append({"role": "user", "content": prompt_with_context})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            chat_history = [
                {"role": convert_role(m["role"]), "parts": [m["content"]]}
                for m in st.session_state.messages
            ]
            chat = genai.GenerativeModel("gemini-2.5-pro").start_chat(history=chat_history)
            response = chat.send_message(prompt_with_context)
            reply = response.text
        except Exception as e:
            reply = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        with st.chat_message("assistant"):
            st.markdown(reply)
        st.session_state.messages.append({"role": "assistant", "content": reply})
