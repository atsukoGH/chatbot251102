import streamlit as st
import google.generativeai as genai

# è¿½åŠ : ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import io
import PyPDF2
import docx

st.title("ğŸ’¬ Chatbot (Gemini 2.5 Pro + ãƒ•ã‚¡ã‚¤ãƒ«è³ªå•å¯¾å¿œ)")
st.write(
    "ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯Google Gemini 2.5 Pro APIã‚’ä½¿ã£ã¦è¿”ç­”ã—ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒ»PDFãƒ»Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€ï¼•è¡Œç¨‹åº¦ã§è¦ç´„ã—ã¾ã™"
)
# Streamlit Community Cloudã®Secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
# .streamlit/secrets.toml ã« GEMINI_API_KEY = "YOUR_API_KEY" ã‚’è¨­å®šã—ã¦ãã ã•ã„
gemini_api_key = st.secrets.get("GEMINI_API_KEY")

uploaded_file = st.file_uploader(
    "è³ªå•ã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆtxt/pdf/docxå¯¾å¿œï¼‰",
    type=["txt", "pdf", "docx"]
)

def extract_text_from_file(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã€‚å¯¾å¿œ: txt, pdf, docx"""
    if uploaded_file is None:
        return None
    name = uploaded_file.name.lower()
    if name.endswith(".txt"):
        try:
            return uploaded_file.read().decode("utf-8")
        except Exception:
            uploaded_file.seek(0)
            return uploaded_file.read().decode("shift-jis", errors="ignore")
    elif name.endswith(".pdf"):
        try:
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() or ""
            return text
        except Exception as e:
            st.error(f"PDFã®èª­ã¿å–ã‚Šã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    elif name.endswith(".docx"):
        try:
            doc = docx.Document(uploaded_file)
            text = "\n".join([para.text for para in doc.paragraphs])
            return text
        except Exception as e:
            st.error(f"Wordãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿å–ã‚Šã§ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    else:
        st.error("æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚")
        return None

if not gemini_api_key:
    st.info("ç¶šè¡Œã™ã‚‹ã«ã¯Gemini APIã‚­ãƒ¼ã‚’secretsã«è¨­å®šã—ã¦ãã ã•ã„ã€‚", icon="ğŸ—ï¸")
else:
    genai.configure(api_key=gemini_api_key)

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "file_content" not in st.session_state:
        st.session_state.file_content = ""
    if "file_summary" not in st.session_state:
        st.session_state.file_summary = ""

    if uploaded_file is not None:
        file_content = extract_text_from_file(uploaded_file)
        st.session_state.file_content = file_content or ""
        if file_content:
            # Geminiã§è¦ç´„
            try:
                model = genai.GenerativeModel("gemini-2.5-pro")
                summary_prompt = (
                    "æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’5è¡Œç¨‹åº¦ã®æ—¥æœ¬èªã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ï¼š\n\n" + file_content
                )
                response = model.generate_content(summary_prompt)
                summary = response.text.strip()
                st.session_state.file_summary = summary
                st.success("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
                st.markdown("#### ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®è¦ç´„ï¼ˆç´„5è¡Œï¼‰")
                st.markdown(summary)
            except Exception as e:
                st.session_state.file_summary = f"è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                st.error(st.session_state.file_summary)
        else:
            st.session_state.file_summary = "ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            st.error(st.session_state.file_summary)

    def convert_role(role):
        if role == "assistant":
            return "model"
        return role

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    prompt = st.chat_input("ã”ç”¨ä»¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if prompt:
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãŒã‚ã‚Œã°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
        context = ""
        if st.session_state.file_content:
            context += f"ã€å‚è€ƒãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã€‘\n{st.session_state.file_content}\n\n"
        prompt_with_context = context + prompt

        st.session_state.messages.append({"role": "user", "content": prompt_with_context})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            chat_history = [
                {"role": convert_role(m["role"]), "parts": [m["content"]]}
                for m in st.session_state.messages
            ]
            chat = genai.GenerativeModel("gemini-2.5-pro").start_chat(history=chat_history)
            response = chat.send_message(prompt_with_context)
            reply = response.text
        except Exception as e:
            reply = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        with st.chat_message("assistant"):
            st.markdown(reply)
        st.session_state.messages.append({"role": "assistant", "content": reply})
