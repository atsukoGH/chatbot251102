import streamlit as st
import google.generativeai as genai

st.title("ğŸ’¬ Chatbot (Gemini 2.5 Pro + ãƒ•ã‚¡ã‚¤ãƒ«è³ªå•å¯¾å¿œ)")
st.write(
    "ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯Google Gemini 2.5 Pro APIã‚’ä½¿ã£ã¦è¿”ç­”ã—ã¾ã™ã€‚"
    "APIã‚­ãƒ¼ã¯[ã“ã¡ã‚‰](https://aistudio.google.com/app/apikey)ã§å–å¾—ã§ãã¾ã™ã€‚"
)

gemini_api_key = st.text_input("Gemini API Key", type="password")
uploaded_file = st.file_uploader("è³ªå•ã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ã¿å¯¾å¿œï¼‰", type=["txt"])

if not gemini_api_key:
    st.info("ç¶šè¡Œã™ã‚‹ã«ã¯Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", icon="ğŸ—ï¸")
else:
    genai.configure(api_key=gemini_api_key)

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "file_content" not in st.session_state:
        st.session_state.file_content = ""

    if uploaded_file is not None:
        file_content = uploaded_file.read().decode("utf-8")
        st.session_state.file_content = file_content
        st.success("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")

    def convert_role(role):
        if role == "assistant":
            return "model"
        return role

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    prompt = st.chat_input("ã”ç”¨ä»¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if prompt:
        # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãŒã‚ã‚Œã°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
        context = ""
        if st.session_state.file_content:
            context += f"ã€å‚è€ƒãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã€‘\n{st.session_state.file_content}\n\n"
        prompt_with_context = context + prompt

        st.session_state.messages.append({"role": "user", "content": prompt_with_context})
        with st.chat_message("user"):
            st.markdown(prompt)

        try:
            chat_history = [
                {"role": convert_role(m["role"]), "parts": [m["content"]]}
                for m in st.session_state.messages
            ]
            chat = genai.GenerativeModel("gemini-2.5-pro").start_chat(history=chat_history)
            response = chat.send_message(prompt_with_context)
            reply = response.text
        except Exception as e:
            reply = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

        with st.chat_message("assistant"):
            st.markdown(reply)
        st.session_state.messages.append({"role": "assistant", "content": reply})
